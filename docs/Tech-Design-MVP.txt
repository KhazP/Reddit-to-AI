Part 2: Technical Design Document (Tech Design Doc) - MVP

1. System Overview

High-level description: "Reddit AI Tool" is a Chrome browser extension built using Manifest V3. It allows users to scrape content from an active Reddit thread and automatically paste it into the Gemini AI chat interface. The extension will consist of a service worker for background logic, content scripts for interacting with Reddit and Gemini web pages, and a browser action popup for user interaction. Data transfer between components will utilize chrome.storage.local.
Platform: Google Chrome Extension (Manifest V3).
2. Tech Stack

Manifest Version: Manifest V3
Core Logic & UI: Vanilla JavaScript (ECMAScript 6+)
Frontend (Popup): HTML, CSS, Vanilla JavaScript
Build Tools: None explicitly required for MVP (manual packaging)
APIs:
Chrome Extension APIs: chrome.tabs, chrome.storage, chrome.scripting, chrome.notifications, chrome.action, chrome.runtime.
AI Model/API: No direct AI model API integration. The extension interacts with the Gemini web UI (https://gemini.google.com/app) via DOM manipulation.
Other Tools/Libraries: None for MVP to minimize dependencies (as per DeepResearch.txt, Source 198).
3. Architecture & Data Flow

Key Components:
Browser Action & Popup (popup.js, popup.html, popup.css): Provides the user interface with the "Scrape and Send to Gemini" button and the comment inclusion toggle. Initiates the scraping process by messaging the service worker.
Service Worker (service_worker.js):
Receives requests from the popup.
Coordinates the scraping and pasting process.
Injects the Reddit content script using chrome.scripting.executeScript.
Receives scraped data from redditScraper.js via chrome.runtime.sendMessage.
Stores scraped data temporarily in chrome.storage.local (as recommended in DeepResearch.txt, Source 117).
Opens a new tab for Gemini using chrome.tabs.create.
Injects the Gemini interaction script into the Gemini tab once loaded.
Reddit Content Script (redditScraper.js):
Injected into the active Reddit tab.
Traverses the DOM to extract post title, subreddit, URL, main content (text, image URLs, link URLs).
Handles dynamic comment loading (e.g., "load more comments" buttons, potentially using MutationObserver as discussed in DeepResearch.txt, Sources 34-42).
Extracts all comments and replies, respecting the user's choice on hidden/spam comments.
Structures data into a JSON object.
Sends the scraped data to the service worker.
Gemini Interaction Script (dynamically injected function via chrome.scripting.executeScript):
Injected into the Gemini tab.
Retrieves scraped data from chrome.storage.local.
Formats data into a plain text string.
Locates the chat input DOM element on the Gemini page.
Programmatically pastes the content, dispatching necessary events (e.g., 'input', 'focus') to ensure UI recognition (as per DeepResearch.txt, Sources 73-77).
Data Flow Diagram/Description:
User clicks browser action button, opening popup.html.
User clicks "Scrape and Send to Gemini" in popup. Popup sends message to service_worker.js.
service_worker.js injects redditScraper.js into the current Reddit tab.
redditScraper.js scrapes data, sends it as a JSON object to service_worker.js via chrome.runtime.sendMessage.
service_worker.js stores this data in chrome.storage.local({ redditThreadData: ... }).
service_worker.js opens https://gemini.google.com/app in a new tab.
Once the Gemini tab is loaded, service_worker.js injects a script into it.
The injected script retrieves redditThreadData from chrome.storage.local.
The script formats the data and attempts to paste it into Gemini's input field.
service_worker.js may clear redditThreadData from chrome.storage.local afterwards.
4. Feature Implementation Notes

Reddit Post & Comment Scraping:
Utilize document.querySelectorAll with robust selectors (e.g., data-testid, ARIA roles, stable structural patterns) to avoid issues with dynamic class names (as advised in DeepResearch.txt, Sources 46, 144, 178).
For "load more comments" and hidden replies, implement logic to simulate clicks and use MutationObserver to handle dynamically added content (DeepResearch.txt, Sources 31-42, 146, 179).
The option to include/exclude hidden/spam comments will require conditional logic in the scraper.
Open AI Platform (Gemini): Use chrome.tabs.create({ url: "https://gemini.google.com/app", active: true }). Ensure the tab is fully loaded (chrome.tabs.onUpdated listener for status === 'complete') before injecting interaction scripts (DeepResearch.txt, Sources 66, 70).
Content Pasting (Gemini):
This is a high-risk area (DeepResearch.txt, Sources 149-152, 211, 213).
The injected script will need to:
Reliably identify Gemini's chat input field (selector needs careful inspection and testing, as it can change).
Focus the element (element.focus()).
Set its value/textContent.
Dispatch an 'input' event (element.dispatchEvent(new Event('input', { bubbles: true }))) and potentially other events to ensure Gemini's framework recognizes the change (DeepResearch.txt, Source 76-77, 151).
Early prototyping of this specific interaction is critical, as noted in DeepResearch.txt (Source 190-195).
UI Popup & Options: Simple HTML/CSS/JS for the popup. The toggle state will be passed to the service worker. The "Options" button will be a UI element without backend logic for MVP.
5. Error Handling

Implement basic error handling using try...catch blocks in critical sections (scraping, pasting).
Use chrome.notifications.create to display user-friendly error messages for critical failures (e.g., "Failed to scrape Reddit content," "Could not interact with Gemini. The site may have updated.") (DeepResearch.txt, Sources 162, 176).
Log errors to the extension's console for debugging.
The service worker should handle failures in one step (e.g., if Gemini tab fails to load or pasting fails) gracefully, potentially notifying the user and stopping the process for that attempt.
6. Data Handling & Security

Scraped Reddit content will be stored temporarily in chrome.storage.local solely for passing data between the service worker and the content script injected into the Gemini tab.
Data in chrome.storage.local will be cleared after the operation is completed or fails (DeepResearch.txt, Source 137).
No user data or scraped content will be transmitted to any third-party servers by the extension itself (it is only programmatically pasted into the client-side Gemini interface).
Permissions will be requested minimally, following Manifest V3 guidelines (e.g., activeTab, scripting, storage, notifications). host_permissions will be limited to *://*.reddit.com/* if manifest-declared content scripts are used, or rely on activeTab for user-invoked actions. Specific AI site permissions might be needed if programmatic injection always requires them beyond activeTab context switching. Given Gemini is the target, https://gemini.google.com/* might be needed for reliable script injection after tab creation.
7. Development Timeline

User Estimated Time: 1 week (max).
Note: This is an ambitious timeline. The technical feasibility assessment (DeepResearch.txt, Sources 190, 218) highlights that interaction with AI UIs (especially Gemini) is high-risk and may require significant prototyping and iteration. Thorough testing of the Reddit scraper across various thread types is also important.